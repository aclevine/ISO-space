-- VERSION_4
-- START DISKCACHE
D:\Program Files\ISO-Space\.metadata\.plugins\org.eclipse.core.resources\.projects\parser\com.python.pydev.analysis\v2_indexcache
scratch|1410285941804|D:\Program Files\ISO-Space\parser\scratch.py
Corpora.mae_document|1410283398016|D:\Program Files\ISO-Space\parser\Corpora\mae_document.py
util.evaluator|1410281326458|D:\Program Files\ISO-Space\parser\util\evaluator.py
Corpora.__init__|1410281213069|D:\Program Files\ISO-Space\parser\Corpora\__init__.py
SKClassifier|1410281459755|D:\Program Files\ISO-Space\parser\SKClassifier.py
Corpora.tokenizer|1409941902512|D:\Program Files\ISO-Space\parser\Corpora\tokenizer.py
util.alphabet|1410281326424|D:\Program Files\ISO-Space\parser\util\alphabet.py
Corpora.stats|1409941902508|D:\Program Files\ISO-Space\parser\Corpora\stats.py
util.__init__|1410281326488|D:\Program Files\ISO-Space\parser\util\__init__.py
Corpora.abbreviation|1409941902458|D:\Program Files\ISO-Space\parser\Corpora\abbreviation.py
Corpora.corpus|1409946751905|D:\Program Files\ISO-Space\parser\Corpora\corpus.py
Corpora.annotation_manager|1409941902474|D:\Program Files\ISO-Space\parser\Corpora\annotation_manager.py
Corpora.mae_corpus|1409941902500|D:\Program Files\ISO-Space\parser\Corpora\mae_corpus.py
Corpora.trial_counts|1409941902532|D:\Program Files\ISO-Space\parser\Corpora\trial_counts.py
Corpora.count_tags|1409941902496|D:\Program Files\ISO-Space\parser\Corpora\count_tags.py
-- END DISKCACHE
-- START DICTIONARY
39
19=TokenizedSentence
35=Tokenizer.__init__
9=util.evaluator
27=TokenizedLex.__init__
11=Corpora.abbreviation
23=UnsupportedMIMETypeError
29=SKClassifier.load_model
2=Corpora.annotation_manager
20=TokenizedLex
37=Document.__init__
30=Tokenizer._set_tag_indexes
13=Corpora.mae_document
26=TokenizedSentence.__init__
34=ConfusionMatrix.__init__
6=SKClassifier
28=SKClassifier.__init__
32=MAE_Document.__init__
12=Corpora.trial_counts
24=Alphabet.__init__
33=UnsupportedMIMETypeError.__init__
36=Tokenizer.tokenize_text
8=Corpora.count_tags
14=Alphabet
7=scratch
17=Tokenizer
38=TokenizedText.__init__
21=ConfusionMatrix
16=Document
5=util.alphabet
3=Corpora.stats
1=Corpora.corpus
22=MAE_Document
10=Corpora.mae_corpus
15=Corpus
4=Corpora.tokenizer
31=Corpus.__init__
18=TokenizedText
25=Alphabet.__eq__
39=Tokenizer._split_contractions
-- END DICTIONARY
-- START TREE 1
62
__a|3|__author__!11@__author__!19@__author__!27@
__e|3|__email__!19@__email__!27@__email__!11@
abb|1|abbrev_pattern!35@
alp|1|Alphabet!41@
ann|2|annotator!19@annotators!19@
apo|1|apostrophe_pattern!35@
bas|1|base_path!19@
bod|1|body!50@
c|1|c!59@
cle|3|clef_corpus!67@clef_corpus_directory!67@clef_corpus_files!67@
clo|1|close_tag!10@
con|3|contraction_pattern1!35@ConfusionMatrix!73@contraction_pattern2!35@
cor|4|corpus!19@Corpus!81@corpora!67@Corpus!9@
cp_|3|cp_corpus_files!67@cp_corpus!67@cp_corpus_directory!67@
dat|2|data!67@datum!67@
dic|3|dict_initial_tokens!91@dict_abbrevs!91@dict_end_abbrevs!91@
dir|1|directory!99@
do|0|
doc|2|Document!9@doc!59@
fil|1|files!99@
fin|1|find_files!10@
geo|1|geo!91@
get|5|get_tag_span!106@get_section!18@get_element_span!106@get_wordnet_pos!106@get_tag_attributes!106@
hom|2|home!19@home!27@
in_|1|in_file!35@
ini|2|initial_tokens_brown!91@initial_tokens_other!91@
is_|2|is_xml!10@is_type!106@
lab|1|label!50@
lex|1|lex_tokenize!106@
lin|1|lines!19@
mae|1|MAE_Document!105@
mai|1|main!26@
mak|2|make_xml!10@make_dir!18@
mat|1|matrix_to_string!74@
mea|1|measures!91@
mon|1|months!91@
ort|1|orth!106@
oth|2|other!91@other_end!91@
par|1|parse!19@
pat|1|pattern!19@
pos|1|pos_tag!106@
pun|1|punctuation_pattern!35@
rfc|3|rfc_corpus_directory!67@rfc_corpus!67@rfc_corpus_files!67@
run|1|run!18@
sen|1|sentences!27@
skc|1|SKClassifier!49@
spa|3|space_eval_path!27@span_in_span!106@SpaceEval!27@
sta|1|states!91@
t|0|
t1|1|t1!35@
tag|3|tag_set!67@tag_types!67@tags!59@
tes|2|test_space!34@test_nonspace!34@
tex|4|text!19@texts!27@text_path!19@text!35@
tit|1|titles!91@
tk|1|tk!35@
tok|8|TokenizedSentence!33@TokenizedText!33@Tokenizer!33@TokenizedLex!33@tokenizers!27@token_is_abbreviation!34@tokenized_texts!27@token!50@
tri|2|trial_files!67@trial_directory!67@
uns|1|UnsupportedMIMETypeError!105@
val|1|validate_mime_type!10@
wor|1|words!27@
wra|1|wrap!10@
x|0|
-- END TREE
-- START TREE 2
63
__e|1|__eq__!14&42@
__i|12|__init__!15&10@__init__!16&10@__init__!14&42@__init__!17&34@__init__!18&34@__init__!19&34@__init__!20&34@__init__!6&50@__init__!21&74@__init__!22&106@__init__!23&106@__init__!15&82@
__l|1|__len__!14&42@
__r|1|__repr__!16&10@
__s|2|__str__!23&106@__str__!20&34@
_fi|1|_first_token_start!17&34@
_in|1|_index_to_label!24&43@
_la|2|_label_to_index!24&43@_label_to_index!25&43@
_re|1|_restore_abbreviation!17&34@
_se|3|_set_lexes!17&34@_set_tag_indexes!17&34@_set_sentences!17&34@
_sl|1|_slurp!17&34@
_sp|4|_split_punctuation!17&34@_split_word!17&34@_split_contractions!17&34@_split_contraction!17&34@
add|3|add_data!21&74@add!14&42@add_labels!6&50@
app|1|append!19&34@
as_|9|as_vertical_string!18&34@as_vertical_string!19&34@as_vertical_string!20&34@as_pairs!18&34@as_pairs!19&34@as_pairs!20&34@as_string!18&34@as_string!19&34@as_string!20&34@
beg|2|begin!26&35@begin!27&35@
cla|1|classify!6&50@
clf|2|clf!28&51@clf!29&51@
clo|2|closing_sents!30&35@closing_lexes!30&35@
col|3|collect_sentences!15&82@collect_documents!15&82@collect_tags!15&82@
com|4|compute_f1!21&74@compute_recall!21&74@compute_precision!21&74@compute_accuracy!21&74@
con|1|consuming_tags!16&10@
dir|1|directory!31&11@
doc|5|doc_id!32&107@documents!31&83@documents!15&10@doc_type!32&107@doc_type!33&107@
end|2|end!26&35@end!27&35@
eva|1|evaluate!6&50@
ext|2|extract_text!22&106@extract_tags!22&106@
fea|4|featurize!6&50@features!29&51@features!28&51@feature_funcs!28&51@
fro|1|from_dict!14&42@
get|6|get_label!14&42@get_tokenized_as_xml!17&34@get_doc_id!22&106@get_index!14&42@get_tokenized!17&34@get_tokenized_as_string!17&34@
has|1|has_label!14&42@
in_|0|
ind|2|index_sentences!22&106@indexed_sentences!32&107@
jso|2|json_dumps!14&42@json_loads!14&42@
lab|3|label_codebook!34&75@labels!28&51@labels!29&51@
len|1|length!35&35@
lex|2|lexes!35&35@lexes!36&35@
loa|1|load_model!6&50@
mat|1|matrix!34&75@
mod|2|model_info!28&51@model_info!29&51@
nam|1|name!37&11@
num|2|num_labels!24&43@num_labels!25&43@
ope|2|opening_lexes!30&35@opening_sents!30&35@
pat|3|paths!31&83@path!32&107@pattern!31&11@
pri|7|print_out!21&74@print_as_string!20&34@print_as_string!19&34@print_as_string!18&34@print_as_xmlstring!18&34@print_as_xmlstring!20&34@print_as_xmlstring!19&34@
rec|1|recursive!31&11@
roo|1|root!16&10@
sav|1|save_model!6&50@
sen|5|sentences!35&35@sentences!36&35@sentences!38&35@sentences!31&83@sentences!32&107@
set|1|set_doc_type!22&106@
siz|1|size!14&42@
slu|1|slurp_token!17&34@
sup|1|supported_doc_types!32&107@
t1|0|
tag|8|tag_types!31&83@tags!31&83@tag_dictionary!31&83@tags!16&10@tag_set!15&82@tag_counts!15&82@tag_dict!15&82@tags!32&107@
tas|1|task!16&10@
tex|4|text!35&35@text!27&35@text!32&107@text!16&10@
tk|0|
to_|1|to_dict!14&42@
tok|6|tokens!35&35@tokens!36&35@tokens!39&35@tokens!26&35@tokenizer!32&107@tokenize_text!17&34@
tra|1|train!6&50@
uni|1|unicode_text!35&35@
val|2|validate!15&10@validate!16&10@
-- END TREE
